import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from dotenv import load_dotenv
import os

# --- ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ ---
load_dotenv()

# --- Streamlitã®UI ---
st.title("ğŸ’¬ LLMæ­è¼‰Webã‚¢ãƒ—ãƒªï¼ˆStreamlit + LangChainï¼‰")
st.write("ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€å°‚é–€å®¶ã®ã‚¿ã‚¤ãƒ—ã‚’é¸ã‚“ã§AIã«è³ªå•ã§ãã¾ã™ã€‚")

# --- å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ ---
expert = st.radio(
    "AIã«ã©ã‚“ãªå°‚é–€å®¶ã¨ã—ã¦å›ç­”ã—ã¦ã»ã—ã„ã§ã™ã‹ï¼Ÿ",
    ("å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼", "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ", "è‹±ä¼šè©±è¬›å¸«")
)

# --- è³ªå•å…¥åŠ› ---
user_input = st.text_area("ã‚ãªãŸã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

# --- LLMå‘¼ã³å‡ºã—é–¢æ•° ---
def ask_ai(role, question):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
    system_message = SystemMessage(content=f"ã‚ãªãŸã¯å„ªç§€ãª{role}ã§ã™ã€‚")
    user_message = HumanMessage(content=question)
    response = llm.invoke([system_message, user_message])
    return response.content

# --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
if st.button("AIã«èã"):
    if not user_input:
        st.warning("âš ï¸ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not os.getenv("OPENAI_API_KEY"):
        st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
            answer = ask_ai(expert, user_input)
            st.success("âœ… å›ç­”:")
            st.write(answer)

